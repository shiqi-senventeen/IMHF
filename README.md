
# Integrated Multimodal Hierarchical Fusion and Meta-Learning for Enhanced Molecular Property Prediction

![Overview](overview.png)
This repository contains the full code and partial sample data for our paper:
**"Integrated Multimodal Hierarchical Fusion and Meta-Learning for Enhanced Molecular Property Prediction."**

We propose a multimodal hierarchical fusion framework that integrates molecular graphs and images, enhanced with meta-learning to improve molecular property prediction performance.

> ‚ö†Ô∏è Due to storage constraints, only a subset of molecular images is included here. The complete dataset, including molecular images, SMILES files, and pretrained weights, can be downloaded via the following links:

* **Baidu Netdisk**: [IMHF.zip (extraction code: 8qfp)](https://pan.baidu.com/s/1pbiOSKRX3QwnWk5qNJC1pA?pwd=8qfp)
* **Google Drive**: [Download Link](https://drive.google.com/file/d/1uuCCjxb9eG9-uTKsxl02--fgUL1iA8NF/view?usp=sharing)

---

## üìÅ Project Structure

```
.
‚îú‚îÄ‚îÄ Module/                # Model components
‚îú‚îÄ‚îÄ Reptile/               # Meta-learning (Reptile algorithm)
‚îú‚îÄ‚îÄ checkpoints/           # Folder for pretrained or saved model weights
‚îú‚îÄ‚îÄ datasets/              # Data loading and processing
‚îú‚îÄ‚îÄ utils/                 # Utility scripts
‚îú‚îÄ‚îÄ cnn_pretrain.py        # CNN pretraining script
‚îú‚îÄ‚îÄ config.py              # Global configuration
‚îú‚îÄ‚îÄ environment.yaml       # Conda environment definition
‚îú‚îÄ‚îÄ finetune.py            # Fine-tuning on downstream tasks
‚îú‚îÄ‚îÄ meta_train.py          # Meta-learning training script
‚îî‚îÄ‚îÄ README.md              # Project documentation
```

---

## ‚öôÔ∏è Environment Setup

You can install required packages by either using the provided `environment.yaml` or manually installing the following dependencies:

### Option 1: Conda environment (recommended)

```bash
conda env create -f environment.yaml
conda activate mols
```

### Option 2: Manual installation

```bash
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
conda install -c conda-forge rdkit
pip install opencv-python
pip install scikit-learn
pip install seaborn
pip install tqdm
pip install einops
pip install nvitop
pip install hausdorff
pip install numba
pip install -U scikit-image
pip install tensorboard==1.1
```

---

## üöÄ Usage Instructions

### Step 1: Prepare Dataset

Download and extract the dataset and checkpoints. Place all files according to the project‚Äôs directory structure. Make sure datasets are inside the `datasets/` folder and follow the correct hierarchy.

---

### Step 2: Pretrain the CNN (Optional)

Pretrain the image feature extractor (CNN):

```bash
python cnn_pretrain.py
```

Alternatively, use the provided pretrained CNN weights:

```
./checkpoints/CNN/cnn.pth
```

---

### Step 3: Meta-Learning Pretraining

Train the model using meta-learning:

```bash
python meta_train.py
```

Ensure the following is set in `config.py`:

```python
ismetatrain = True
```

Or load pretrained meta-model:

```
./checkpoints/pretain.pth
```

---

### Step 4: Fine-Tune on Downstream Tasks

Edit the configuration:

```python
ismetatrain = False
task_name = "BBBP"  # Options: bace, tox21, clintox, etc.
```

Then run:

```bash
python finetune.py
```

Results including ROC-AUC, accuracy, and F1 score will be printed and saved.

---

## ‚öôÔ∏è Configuration Guide (`config.py`)

The `config.py` file contains all hyperparameters. Here's how to adjust them for different phases:

### ‚úÖ General Settings

| Parameter     | Description                                       | Value                         |
| ------------- | ------------------------------------------------- | ----------------------------- |
| `ismetatrain` | `True` for meta-training, `False` for fine-tuning | `True` / `False`              |
| `task_name`   | Dataset name (for fine-tuning)                    | `"bace"`, `"tox21"` etc.      |
| `pretain_pth` | Pretrained model path                             | `"./checkpoints/pretain.pth"` |

### üìò Meta-Learning Settings

| Parameter      | Description              | Default |
| -------------- | ------------------------ | ------- |
| `meta_batchsz` | Tasks per meta-batch     | 2       |
| `meta_lr`      | Outer loop learning rate | 0.001   |
| `num_updates`  | Inner loop updates       | 5       |
| `meta_epoch`   | Meta-training epochs     | 10      |

### üìï Fine-Tuning Settings

| Parameter     | Description           | Default |
| ------------- | --------------------- | ------- |
| `epoch`       | Total training epochs | 100     |
| `random_seed` | Random seed           | 68      |

### üß† Model Architecture

| Parameter       | Description                    | Default |
| --------------- | ------------------------------ | ------- |
| `gnn_num_layer` | Number of GNN layers           | 3       |
| `p_dropout`     | Dropout rate                   | 0.2     |
| `imgsize`       | Input image size               | 224     |
| `img_dim`       | Image feature dimension        | 768     |
| `node_dim`      | Node latent dimension          | 256     |
| `edge_dim`      | Edge latent dimension          | 64      |
| `en_node_dim`   | Initial node feature dimension | 31      |
| `en_edge_dim`   | Initial edge feature dimension | 6       |

---

## üß™ Implementation Details

Our training process consists of two main stages: **meta-learning pretraining** and **fine-tuning on downstream property prediction tasks**.

### üîÅ Meta-Learning Pretraining

We adopt the Reptile meta-learning algorithm. This phase helps the model learn transferable molecular representations from auxiliary datasets.

| Parameter      | Value | Description                    |
| -------------- | ----- | ------------------------------ |
| `meta_batchsz` | 2     | Number of tasks per meta-batch |
| `meta_lr`      | 0.001 | Outer loop learning rate       |
| `num_updates`  | 5     | Number of inner-loop updates   |
| `meta_epoch`   | 10    | Total meta-training epochs     |

Run the training using:

```bash
python meta_train.py
```

Ensure the following flag is set in `config.py`:

```python
ismetatrain = True
```

### üéØ Fine-Tuning on Downstream Tasks

After meta-training, we fine-tune the model on disjoint benchmark datasets such as BBBP, BACE, Tox21, etc.

| Parameter     | Value  | Description                  |
| ------------- | ------ | ---------------------------- |
| `epoch`       | 100    | Total fine-tuning epochs     |
| `random_seed` | 68     | Seed for reproducibility     |
| `task_name`   | "BBBP" | Target task name             |
| `ismetatrain` | False  | Switches to fine-tuning mode |

Run fine-tuning with:

```bash
python finetune.py
```

### üß© Model Architecture

Our IMHF framework integrates multimodal information from both molecular graphs and images. The architecture uses a hierarchical fusion mechanism with the following major modules:

| Component       | Value | Description                          |
| --------------- | ----- | ------------------------------------ |
| `gnn_num_layer` | 3     | Number of GNN layers                 |
| `node_dim`      | 256   | Node hidden dimension                |
| `edge_dim`      | 64    | Edge hidden dimension                |
| `en_node_dim`   | 31    | Initial node feature dimension       |
| `en_edge_dim`   | 6     | Initial edge feature dimension       |
| `p_dropout`     | 0.2   | Dropout rate                         |
| `imgsize`       | 224   | Input molecular image size           |
| `img_dim`       | 768   | Image feature dimension (CNN output) |

---
## üß™ Experimental Results

Here‚Äôs the comparison of the ROC-AUC values achieved by various methods on molecular property prediction tasks:

| Model                        | #Param   | BACE     | BBBP     | HIV      | ClinTox  | Tox21 | Avg. |
| ---------------------------- | -------- | -------- | -------- | -------- | -------- | ----- | ---- |
| GIN                          | 5.1M     | 0.72     | 0.70     | 0.69     | 0.61     | 0.75  | 0.69 |
| AttMask                      | 5.2M     | 0.79     | 0.64     | 0.65     | 0.61     | 0.74  | 0.68 |
| GPTGNN                       | 5.5M     | 0.72     | 0.69     | 0.72     | 0.69     | 0.73  | 0.69 |
| ConPred                      | 8.5M     | 0.77     | 0.68     | 0.69     | 0.71     | 0.72  | 0.71 |
| InfoG                        | 6.5M     | 0.76     | 0.69     | 0.73     | 0.73     | 0.75  | 0.73 |
| MoCL                         | 10.5M    | 0.75     | 0.66     | 0.69     | 0.60     | 0.71  | 0.68 |
| GrLoG                        | 11M      | 0.79     | 0.65     | 0.61     | 0.73     | 0.73  | 0.70 |
| GraphCL                      | 7.5M     | 0.73     | 0.67     | 0.71     | 0.78     | 0.75  | 0.73 |
| JOAO                         | 13M      | 0.72     | 0.70     | 0.66     | 0.79     | 0.75  | 0.72 |
| MolCLR                       | 9.2M     | 0.76     | 0.69     | 0.71     | **0.83** | 0.74  | 0.75 |
| G\_Motif                     | 7.3M     | **0.83** | 0.68     | 0.72     | 0.78     | 0.73  | 0.75 |
| MGSSL                        | 15M      | 0.79     | 0.69     | 0.74     | 0.80     | 0.76  | 0.76 |
| MetaGIN                      | 17M      | -        | **0.80** | -        | **0.83** | 0.78  | -    |
| MMGCF                        | -        | -        | **0.85** | 0.80     | -        | -     | -    |
| G\_SAGE                      | 5.0M     | 0.72     | 0.67     | 0.68     | 0.52     | 0.69  | 0.66 |
| Himol(S)                     | 3.4M     | 0.78     | 0.68     | 0.72     | 0.70     | 0.71  | 0.72 |
| Himol(L)                     | 5.5M     | 0.79     | 0.71     | 0.78     | 0.80     | 0.74  | 0.76 |
| **Meta-model**               | **0.3M** | 0.78     | 0.74     | 0.74     | 0.75     | 0.76  | 0.75 |
| **Ours**                     | **0.3M** | **0.83** | 0.78     | **0.82** | **0.83** |**0.79**| **0.81** |

---

## üì´ Contact

For questions, suggestions, or issues, please open an issue or contact the authors.
